{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from matrix_factorization import MatrixFactorization\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "from scipy import *\n",
    "import tool_function as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FDTree Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import find\n",
    "from copy import deepcopy\n",
    "from matrix_factorization import MatrixFactorization\n",
    "\n",
    "class DecisionTreeModel:\n",
    "    def __init__(self, sMatrix, depth_threshold=6, plambda=7):\n",
    "        '''\n",
    "            sMatrix: I*U matrix\n",
    "            depth_threshold: terminate depth\n",
    "            plambda: regularization parameter\n",
    "            self.rI: dict { \n",
    "                        itemid1: [ [uid11, rating11], [uid12, rating12], ... ] rating for item 1\n",
    "                        itemid2: [ [uid21, rating21], [uid22, rating22], ... ] rating for item 2\n",
    "                        itemid3: ...\n",
    "                     }\n",
    "            self.rU: dict {\n",
    "                        userid1: { itemid11: rating11, itemid12: rating12, ... } rating of user 1\n",
    "                        userid2: { itemid21: rating21, itemid22: rating22, ... } rating of user 2\n",
    "                        userid3: ...\n",
    "                     }\n",
    "            self.lr_bound: dict {\n",
    "                                level 0: [[left_bound, right_bound]], users' bound for one level, each ele in dictionary represents one node\n",
    "                                level 1: [[left_bound, right_bound], [left_bound, right_bound], [left_bound, right_bound]], 3\n",
    "                                level 2: ..., 9\n",
    "                            } (bound means index)\n",
    "            self.tree: []  all of userid\n",
    "            self.split_item: list [\n",
    "                    level 0: []\n",
    "                    level 1: []\n",
    "                    level 2: []\n",
    "            ]\n",
    "            self.sum_cur_t: dict {\n",
    "                        itemid1: {'rating': sum of ratings for item 1, 'cnt': sum of users rated item 1}\n",
    "                        itemid2: {'rating': sum of ratings for item 2, 'cnt': sum of users rated item 2}\n",
    "                        ...\n",
    "                    }\n",
    "            self.sum_2_cur_t: dict {\n",
    "                        itemid1: sum of square ratings for item 1\n",
    "                        itemid2: sum of square ratings for item 2\n",
    "                        ...\n",
    "                    }\n",
    "            self.biasU: dict {\n",
    "                        userid1: bias1\n",
    "                        userid2: bias2\n",
    "                        ...\n",
    "                    }\n",
    "            self.user_profile: dict {\n",
    "                        level 0: {pseudo_user1: [k1, k2, k3, ... , kt]}\n",
    "                        level 1: {pseudo_user1: [k1, k2, k3, ... , kt], pseudo_user2: [k1, k2, k3, ... , kt], pseudo_user3: [k1, k2, k3, ... , kt]}\n",
    "                        ... \n",
    "                    } profile for each level's node\n",
    "            self.item_profile: dict {\n",
    "                        level 0: [[k1, k2, k3, ... , kt], [k1, k2, k3, ... , kt], [k1, k2, k3, ... , kt], ...] for each item\n",
    "                        level 1: [[k1, k2, k3, ... , kt], [k1, k2, k3, ... , kt], [k1, k2, k3, ... , kt], ...] for each item\n",
    "                        ...\n",
    "                    } profile for each item\n",
    "            every element represents ratings for one item, its order decide the users in tree nodes\n",
    "        '''\n",
    "        self.item_size = sMatrix.shape[0]\n",
    "        self.user_size = sMatrix.shape[1]\n",
    "        self.depth_threshold = depth_threshold\n",
    "        self.plambda = plambda\n",
    "        self.cur_depth = 0\n",
    "        x = find(sMatrix)\n",
    "        itemset = x[0]\n",
    "        userset = x[1]\t\n",
    "        self.rI = {}\n",
    "        self.rU = {}\t\n",
    "        self.sum_cur_t = {}\n",
    "        self.sum_2_cur_t = {}\n",
    "        # self.rI[itemset[0]] = [[userset[0], sMatrix[itemset[0], userset[0]]]]\n",
    "        # self.rU[userset[0]] = {itemset[0]: sMatrix[itemset[0], userset[0]]}\n",
    "        self.global_mean = 0                   # global average of ratings\n",
    "\n",
    "        #### Calculate rate of progress ####\n",
    "        self.node_num = 0\n",
    "        self.cur_node = 0\n",
    "        for i in range(self.depth_threshold):\n",
    "            self.node_num += pow(3, i)\n",
    "\n",
    "        #### Generate rI, rU ####\n",
    "        for itemid, userid in zip(itemset, userset):\n",
    "            self.rU.setdefault(userid, {})[itemid] = sMatrix[itemid, userid]\n",
    "            self.rI.setdefault(itemid, []).append([userid, sMatrix[itemid, userid]])\n",
    "            self.global_mean += sMatrix[itemid, userid]\n",
    "        self.global_mean /= len(itemset)\n",
    "\n",
    "        #### Initiate Tree, lr_bound ####\n",
    "        self.tree = list(self.rU.keys())\n",
    "        self.split_item = []\n",
    "        self.lr_bound = {'0': [[0, len(self.tree)-1]]}\n",
    "\n",
    "        #### Generate bias, sum_cur_t, sum_2_cur_t ####\n",
    "        self.biasU = {}\n",
    "        for userid in self.rU:\n",
    "            self.biasU[userid] = (sum(list(self.rU[userid].values())) + self.plambda*self.global_mean) / (self.plambda + len(self.rU[userid]))\n",
    "        self.sum_cur_t[itemset[0]] = {'rating': sMatrix[itemset[0], userset[0]]-self.biasU[userset[0]], 'cnt': 1}\n",
    "        self.sum_2_cur_t[itemset[0]] = pow(sMatrix[itemset[0], userset[0]]-self.biasU[userset[0]], 2)\n",
    "        for itemid, userid, ind in zip(itemset[1:],userset[1:],range(1, len(itemset))):\n",
    "            if itemid == itemset[ind-1]:\n",
    "                self.sum_cur_t[itemid]['rating'] += sMatrix[itemid, userid]-self.biasU[userid]\n",
    "                self.sum_cur_t[itemid]['cnt'] += 1\n",
    "                self.sum_2_cur_t[itemid] += pow(sMatrix[itemid, userid]-self.biasU[userid], 2)\n",
    "            else:\n",
    "                self.sum_cur_t[itemid] = {'rating': sMatrix[itemid, userid]-self.biasU[userid], 'cnt': 1}\n",
    "                self.sum_2_cur_t[itemid] = pow(sMatrix[itemid, userid]-self.biasU[userid], 2)\n",
    "\n",
    "        #### Prediction Model ####\n",
    "        self.user_profile = {}\n",
    "        self.item_profile = {}\n",
    "        self.MF = MatrixFactorization()\n",
    "\n",
    "        print(\"Initiation DONE!\")\n",
    "\n",
    "\n",
    "    def calculate_error(self, sumtL, sumtL_2, sumtD, sumtD_2, sumtU, sumtU_2):\n",
    "        ''' Calculate error for one item-split in one node '''\n",
    "        Error_i = 0\n",
    "        for itemid in sumtL:\n",
    "            Error_i += sumtL_2[itemid] - pow(sumtL[itemid]['rating'], 2)/(sumtL[itemid]['cnt']+1e-9) \\\n",
    "                        + sumtD_2[itemid] - pow(sumtD[itemid]['rating'], 2)/(sumtD[itemid]['cnt']+1e-9) \\\n",
    "                            + sumtU_2[itemid] - pow(sumtU[itemid]['rating'], 2)/(sumtU[itemid]['cnt']+1e-9)\n",
    "        return Error_i\n",
    "\n",
    "\n",
    "    def generate_decision_tree(self, lr_bound_for_node, chosen_id):\n",
    "        '''\n",
    "            sumtL: dict {\n",
    "                itemid1: {'rating': sum of ratings for item 1, 'cnt': sum of users rated item 1}\n",
    "                itemid2: {'rating': sum of ratings for item 2, 'cnt': sum of users rated item 2}\n",
    "                ...\n",
    "            }\n",
    "            sumtL_2: dict {\n",
    "                itemid1: sum of square ratings for item 1\n",
    "                itemid2: sum of square ratings for item 2\n",
    "                ...\n",
    "            }\n",
    "            lr_bound_for_node: list [leftind, rightind] for one node\n",
    "        '''\n",
    "\n",
    "        #### Terminate ####\n",
    "        self.cur_depth += 1\n",
    "        if self.cur_depth > self.depth_threshold or len(chosen_id) == self.item_size:\n",
    "            return\n",
    "\n",
    "        #### Find optimum item to split ####\n",
    "        min_sumtL, min_sumtD, min_sumtL_2, min_sumtD_2, min_sumtU, min_sumtU_2, Error = {}, {}, {}, {}, {}, {}, {}\n",
    "        min_Error = \"None\"\n",
    "        for itemid in self.rI:\n",
    "            if itemid in chosen_id:\n",
    "                continue\n",
    "            ''' \n",
    "                user_rating_item_in_nodet: [ [uid01, rating01], [uid02, rating02], ... ] \n",
    "                to find all users in node t who rates item i\n",
    "            '''\n",
    "            user_rating_item_in_nodet = [[userid, self.rU[userid][itemid]] for userid in self.tree[lr_bound_for_node[0]:(lr_bound_for_node[1]+1)] if itemid in self.rU[userid]]\n",
    "            sumtL, sumtD, sumtL_2, sumtD_2, sumtU, sumtU_2 = {}, {}, {}, {}, {}, {}\n",
    "            sumtL = {k:{'rating': 0, 'cnt': 0} for k in self.rI.keys()}\n",
    "            sumtL_2 = sumtL_2.fromkeys(self.rI.keys(), 0)\n",
    "            sumtD = {k:{'rating': 0, 'cnt': 0} for k in self.rI.keys()}\n",
    "            sumtD_2 = sumtD_2.fromkeys(self.rI.keys(), 0)\n",
    "            for user in user_rating_item_in_nodet:\n",
    "                ''' user_all_rating: [ [itemid11, rating11], [itemid12, rating12], ... ] '''\n",
    "                user_all_rating = self.rU[user[0]]\n",
    "                #### calculate sumtL for node LIKE ####\n",
    "                if user[1] >= 4:\n",
    "                    for uritem, rating in user_all_rating.items():\n",
    "                        sumtL[uritem]['rating'] += rating\n",
    "                        sumtL_2[uritem] += pow(rating-self.biasU[user[0]], 2)\n",
    "                        sumtL[uritem]['rating'] -= self.biasU[user[0]]\n",
    "                        sumtL[uritem]['cnt'] += 1\n",
    "                #### calculate sumtD for node DISLIKE ####\n",
    "                elif user[1] <= 3:\n",
    "                    for uritem, rating in user_all_rating.items():\n",
    "                        sumtD[uritem]['rating'] += rating\n",
    "                        sumtD_2[uritem] += pow(rating-self.biasU[user[0]], 2)\n",
    "                        sumtD[uritem]['rating'] -= self.biasU[user[0]]\n",
    "                        sumtD[uritem]['cnt'] += 1\n",
    "            #### calculate sumtU for node UNKNOWN ####\n",
    "            for iid in self.rI:\n",
    "                sumtU[iid] = {}\n",
    "                sumtU[iid]['rating'] = self.sum_cur_t[iid]['rating'] - sumtL[iid]['rating'] - sumtD[iid]['rating']\n",
    "                sumtU[iid]['cnt'] = self.sum_cur_t[iid]['cnt'] - sumtL[iid]['cnt'] - sumtD[iid]['cnt']\n",
    "                sumtU_2[iid] = self.sum_2_cur_t[iid] - sumtL_2[iid] - sumtD_2[iid]\n",
    "            #### calculate error by (eL + eD + eU) ####\n",
    "            Error[itemid] = self.calculate_error(sumtL, sumtL_2, sumtD, sumtD_2, sumtU, sumtU_2)\n",
    "            if min_Error == \"None\" or Error[itemid] < min_Error:\n",
    "                min_sumtL = deepcopy(sumtL)\n",
    "                min_sumtD = deepcopy(sumtD)\n",
    "                min_sumtU = deepcopy(sumtU)\n",
    "                min_sumtL_2 = sumtL_2.copy()\n",
    "                min_sumtD_2 = sumtD_2.copy()\n",
    "                min_sumtU_2 = sumtU_2.copy()\n",
    "                min_Error = Error[itemid]\n",
    "        #### Find optimum split-item ####\n",
    "        optimum_itemid = min(Error, key=Error.get)\n",
    "        if len(self.split_item) == self.cur_depth-1:\n",
    "            self.split_item.append([optimum_itemid])\n",
    "        else:\n",
    "            self.split_item[self.cur_depth-1].append(optimum_itemid)\n",
    "        # self.split_item.setdefault(str(self.cur_depth-1), []).append(optimum_itemid)\n",
    "        chosen_id.append(optimum_itemid)\n",
    "\n",
    "\n",
    "        #### sort tree ####\n",
    "        self.lr_bound.setdefault(str(self.cur_depth), []).append([])                                          # for LIKE\n",
    "        self.lr_bound[str(self.cur_depth)].append([])   \t\t\t\t\t                                  # for DISLIKE\n",
    "        self.lr_bound[str(self.cur_depth)].append([])                                    \t\t\t\t\t  # for UNKNOWN\n",
    "        listU, listL, listD = [], [], []\n",
    "        for userid in self.tree[lr_bound_for_node[0]:(lr_bound_for_node[1]+1)]:\n",
    "            if optimum_itemid not in self.rU[userid]:\n",
    "                listU.append(userid)\n",
    "            elif self.rU[userid][optimum_itemid] >= 4:\n",
    "                listL.append(userid)\n",
    "            elif self.rU[userid][optimum_itemid] <= 3:\n",
    "                listD.append(userid)\n",
    "        self.tree[lr_bound_for_node[0]:(lr_bound_for_node[1]+1)] = listL + listD + listU\n",
    "        self.lr_bound[str(self.cur_depth)][-3] = [lr_bound_for_node[0], lr_bound_for_node[0]+len(listL)-1]                                                     # for LIKE\n",
    "        self.lr_bound[str(self.cur_depth)][-2] = [lr_bound_for_node[0]+len(listL), lr_bound_for_node[0]+len(listL)+len(listD)-1]                                 # for DISLIKE\n",
    "        self.lr_bound[str(self.cur_depth)][-1] = [lr_bound_for_node[0]+len(listL)+len(listD), lr_bound_for_node[0]+len(listL)+len(listD)+len(listU)-1]           # for UNKNOWN\n",
    "\n",
    "\n",
    "        #### Generate Subtree of Node LIKE ####\n",
    "        self.sum_cur_t = deepcopy(min_sumtL)\n",
    "        self.sum_2_cur_t = min_sumtL_2.copy()\n",
    "        self.generate_decision_tree(self.lr_bound[str(self.cur_depth)][-3], chosen_id[:])    \n",
    "        self.cur_depth -= 1\n",
    "\n",
    "        #### Generate Subtree of Node DISLIKE ####\n",
    "        self.sum_cur_t = deepcopy(min_sumtD)\n",
    "        self.sum_2_cur_t = min_sumtD_2.copy()\n",
    "        self.generate_decision_tree(self.lr_bound[str(self.cur_depth)][-2], chosen_id[:])    \n",
    "        self.cur_depth -= 1\n",
    "\n",
    "        #### Generate Subtree of Node UNKNOWN ####\n",
    "        self.sum_cur_t = deepcopy(min_sumtU)\n",
    "        self.sum_2_cur_t = min_sumtU_2.copy()\n",
    "        self.generate_decision_tree(self.lr_bound[str(self.cur_depth)][-1], chosen_id[:])\n",
    "        self.cur_depth -= 1\n",
    "\n",
    "        #### Show Rating Progress ####\n",
    "        for i in range(self.cur_depth - 1):\n",
    "            print(\"┃\", end=\"\")        \n",
    "        print(\"┏\", end=\"\")\n",
    "        self.cur_node += 1\n",
    "        print(\"Current depth: \" + str(self.cur_depth) + \"        %.2f%%\" %(100*self.cur_node/self.node_num))\n",
    "\n",
    "\n",
    "    def calculate_avg_rating_for_pesudo_user(self, pseudo_user_lst):\n",
    "        '''ret_dict: dict {\n",
    "            itemid0: rating0 \n",
    "            itemid1: rating1\n",
    "            ...\t\t\t\t\n",
    "        }'''\n",
    "        cal_dict = {key: {'rating': 0, 'cnt': 0} for key in self.rI}\n",
    "        ret_dict = {}\n",
    "        for userid in pseudo_user_lst:\n",
    "            for itemid, rating in self.rU[userid].items():\n",
    "                cal_dict[itemid]['rating'] += rating\n",
    "                cal_dict[itemid]['cnt'] += 1\n",
    "        for itemid in cal_dict:\n",
    "            if cal_dict[itemid]['cnt'] == 0:\n",
    "                continue\n",
    "            ret_dict[itemid] = cal_dict[itemid]['rating'] / cal_dict[itemid]['cnt']\n",
    "        return ret_dict\n",
    "\n",
    "\n",
    "    def generate_prediction_model(self):\n",
    "        '''self.lr_bound: dict {\n",
    "                    level 0: [[left_bound, right_bound]], users' bound for one level, each ele in dictionary represents one node\n",
    "                    level 1: [[left_bound, right_bound], [left_bound, right_bound], [left_bound, right_bound]], 3\n",
    "                    level 2: ..., 9\n",
    "                } (bound means index)\n",
    "        '''\n",
    "        for level in self.lr_bound:\n",
    "            self.user_profile.setdefault(level)\n",
    "            train_lst = []\n",
    "            for pseudo_user_bound, userid in zip(self.lr_bound[level], range(len(self.lr_bound[level]))):\n",
    "                if pseudo_user_bound[0] > pseudo_user_bound[1]:\n",
    "                    continue\n",
    "                pseudo_user_lst = self.tree[pseudo_user_bound[0]:(pseudo_user_bound[1]+1)]\n",
    "                pseudo_user_for_item = self.calculate_avg_rating_for_pesudo_user(pseudo_user_lst)\n",
    "                train_lst += [(userid, int(key), float(value)) for key, value in pseudo_user_for_item.items()]\n",
    "            self.user_profile[level], self.item_profile[level] = self.MF.matrix_factorization(train_lst)\n",
    "\n",
    "\n",
    "    def build_model(self):\n",
    "        #### Construct the tree & get the prediction model ####\n",
    "        self.generate_decision_tree(self.lr_bound['0'][0], [])\n",
    "        self.generate_prediction_model()\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, new_user_ratings, pred_index):\n",
    "        ''' new_user_ratings: list [\n",
    "                       [itemid1, rating1],\n",
    "                       [itemid2, rating2],\n",
    "                       [itemid3, rating3],\n",
    "                       [itemid4, rating4],\n",
    "                       ... ] \n",
    "            pred_rating: array: (I,)\n",
    "                            new user's rating for each item\n",
    "         '''\n",
    "\n",
    "        #### Find user profile for new user ####\n",
    "        new_user_profile = np.array(self.user_profile[str(len(new_user_ratings))][pred_index])   # shape: (k,)\n",
    "        new_item_profile = np.array(self.item_profile[str(len(new_user_ratings))])               # shape: (I, k)\n",
    "\n",
    "        #### Calculate predict rating ####\n",
    "        pred_rating = np.dot(new_item_profile, new_user_profile)\n",
    "        return pred_rating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MF Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "class MatrixFactorization:\n",
    "    def __init__(self, maxIter = 15, regParam = 0.01, rank = 10):\n",
    "        self.maxIter = maxIter\n",
    "        self.regParam = regParam  \n",
    "        self.rank = rank  \n",
    "        self.spark = SparkSession.builder.master(\"local[*]\").appName(\"Example\").getOrCreate()\n",
    "        \n",
    "    def matrix_factorization(self, train_lst):\n",
    "        \n",
    "        ratings = self.spark.createDataFrame(train_lst)\n",
    "        model = ALS.train(ratings, self.rank, seed=10, \\\n",
    "                          iterations = self.maxIter, \\\n",
    "                          lambda_ = self.regParam)\n",
    "        print(\"MF DONE\")\n",
    "        userFeatures = sorted(model.userFeatures().collect(), key=lambda d:d[0], reverse = False)\n",
    "        productFeatures = sorted(model.productFeatures().collect(), key=lambda d:d[0], reverse = False)\n",
    "        userProfile = {each[0]: each[1].tolist() for each in userFeatures}\n",
    "        itemProfile = [each[1].tolist() for each in productFeatures]\n",
    "            \n",
    "        return userProfile, itemProfile\n",
    "\n",
    "    def end(self):\n",
    "        self.spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import *\n",
    "\n",
    "def RMSE(real_rating, pred_rating, rated_item):\n",
    "    rmse, cnt = 0, 0\n",
    "    for itemid, rating in real_rating.items():\n",
    "        if itemid not in rated_item:\n",
    "            rmse += pow(pred_rating[itemid] - rating, 2)\n",
    "            cnt += 1\n",
    "    return pow(rmse/cnt, 0.5)\n",
    "\n",
    "def pred_RMSE_for_new_item(fdtmodel, sM_testing):\n",
    "    '''\n",
    "        fdtmodel: FDT class instance\n",
    "        sM_testing: 30% test dataset (sparse matrix)\n",
    "        split_item: list [\n",
    "                level 0: [112], \n",
    "                level 1: [48, 0, 79], \n",
    "                level 2: [15, 0, 17, 1, 1, 1, 61, 0, 50]\n",
    "                ...\n",
    "            ]\n",
    "        User: dict {\n",
    "                    userid1: { itemid11: rating11, itemid12: rating12, ... } rating of user 1\n",
    "                    userid2: { itemid21: rating21, itemid22: rating22, ... } rating of user 2\n",
    "                    userid3: ...\n",
    "                }\n",
    "        return : rmse value (float)\n",
    "    '''\n",
    "    x = find(sM_testing)\n",
    "    itemset = x[0]\n",
    "    userset = x[1]\n",
    "    User = {}\n",
    "    for itemid, userid in zip(itemset, userset):\n",
    "        User.setdefault(userid, {})[itemid] = sM_testing[itemid, userid]\n",
    "\n",
    "    rmse = 0\n",
    "    for userid in User:\n",
    "        pred_index = 0\n",
    "        new_user_ratings = []\n",
    "        rated_item = []\n",
    "        for level in range(len(fdtmodel.split_item)):\n",
    "            if fdtmodel.split_item[level][pred_index] not in User[userid]:\n",
    "                tmp_pred_index = 3*pred_index + 2\n",
    "                if tmp_pred_index in fdtmodel.user_profile[str(int(level)+1)]:\n",
    "                    new_user_ratings.append([fdtmodel.split_item[level][pred_index], 0])\n",
    "                    pred_index = tmp_pred_index\n",
    "                else:\n",
    "                    break\n",
    "            elif User[userid][fdtmodel.split_item[level][pred_index]] >= 4:\n",
    "                tmp_pred_index = 3*pred_index\n",
    "                if tmp_pred_index in fdtmodel.user_profile[str(int(level)+1)]:\n",
    "                    rated_item.append(fdtmodel.split_item[level][pred_index])\n",
    "                    new_user_ratings.append([fdtmodel.split_item[level][pred_index], User[userid][fdtmodel.split_item[level][pred_index]]])\n",
    "                    pred_index = tmp_pred_index\n",
    "                else:\n",
    "                    break\n",
    "            elif User[userid][fdtmodel.split_item[level][pred_index]] <= 3:\n",
    "                tmp_pred_index = 3*pred_index + 1\n",
    "                if tmp_pred_index in fdtmodel.user_profile[str(int(level)+1)]:\n",
    "                    rated_item.append(fdtmodel.split_item[level][pred_index])\n",
    "                    new_user_ratings.append([fdtmodel.split_item[level][pred_index], User[userid][fdtmodel.split_item[level][pred_index]]])\n",
    "                    pred_index = tmp_pred_index\n",
    "                else:\n",
    "                    break\n",
    "        pred_rating = fdtmodel.predict(new_user_ratings, pred_index)\n",
    "        rmse += RMSE(User[userid], pred_rating, rated_item)\n",
    "\n",
    "    return rmse / len(User)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Input Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "catagory = \"Movies_and_TV\"\n",
    "item_data = 'item_metadata/meta_' + catagory + '.csv'\n",
    "rating_data = 'user_ratings/' + catagory + '.csv'\n",
    "ratingsFrame = pd.read_csv(rating_data, names = [\"userID\", \"itemID\", \"rating\"])\n",
    "ratingsFrame.sort_values(by = 'userID', ascending=True, inplace=True)\n",
    "itemsFrame = pd.read_csv(item_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Construct User-Item Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_lst = ratingsFrame[\"itemID\"].tolist()\n",
    "user_lst = ratingsFrame[\"userID\"].tolist()\n",
    "rating_lst = ratingsFrame[\"rating\"].tolist()\n",
    "row = []\n",
    "col = []\n",
    "rating_data = []\n",
    "\n",
    "for i in range(ratingsFrame.shape[0]):\n",
    "    col.append(item_lst[i])\n",
    "    row.append(user_lst[i])\n",
    "    rating_data.append(rating_lst[i])\n",
    "    \n",
    "rating_martix_coo = coo_matrix((rating_data, (row, col)), shape=(user_lst[len(user_lst)-1]+1, itemsFrame.shape[0]))\n",
    "rating_martix_csc = rating_martix_coo.tocsc()\n",
    "rating_martix_csr = rating_martix_coo.tocsr()\n",
    "\n",
    "start = 0\n",
    "end = int(rating_martix_csc.shape[1] * 0.7)\n",
    "sM_training = rating_martix_csc[:, start:end]\n",
    "sM_testing =  rating_martix_csc[:, end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00%\n",
      "30.01%\n",
      "60.01%\n",
      "90.02%\n",
      "empty number:  647\n",
      "empty fill DONE\n"
     ]
    }
   ],
   "source": [
    "# empty_lst = []\n",
    "# sM_training = sM_training.tocsr()\n",
    "# for i in range(sM_training.shape[0]):        \n",
    "#     if i % 10000 == 0:\n",
    "#         print(\"%.2f%%\" %(100*i/sM_training.shape[0]))\n",
    "#     if len(sM_training[i].nonzero()[0]) == 0:\n",
    "#         empty_lst.append(i)\n",
    "# print(\"empty number: \", len(empty_lst))\n",
    "# if len(empty_lst) != 0:\n",
    "#     for empty in empty_lst:\n",
    "#         ratingsFrame.drop(ratingsFrame[ratingsFrame.userID==empty].index.tolist(), inplace=True)\n",
    "#     while True:\n",
    "#         lastID = ratingsFrame.iloc[ratingsFrame.shape[0]-1][\"userID\"] \n",
    "#         if empty_lst[0] > lastID:\n",
    "#             break\n",
    "#         ratingsFrame.loc[ratingsFrame[ratingsFrame.userID==lastID].index.tolist(),\"userID\"] = empty_lst[0]\n",
    "#         ratingsFrame.sort_values(by = 'userID', ascending=True, inplace=True)\n",
    "#         if len(empty_lst) == 1:\n",
    "#             break\n",
    "#         else:\n",
    "#             empty_lst = empty_lst[1:]\n",
    "#     print(\"empty fill DONE\")\n",
    "# ratingsFrame.sort_values(by = 'itemID', ascending=True, inplace=True)\n",
    "# if ratingsFrame.groupby(\"itemID\").size().shape[0] != itemsFrame.iloc[itemsFrame.shape[0]-1][\"asin\"] + 1:\n",
    "#     print(\"WARNING! ITEM MISSED AFTER EMPTY DESCARDING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Initialize FDT tree and construct prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-f2cb6d43e5d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdtmodel_realdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msM_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdtmodel_realdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-5460ef1b9752>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sMatrix, depth_threshold, plambda)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitemid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitemset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitemid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msMatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitemid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitemid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muserid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msMatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitemid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_mean\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msMatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitemid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_mean\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitemset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;31m# [i, j]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misintlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_single_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m             \u001b[0;31m# [i, 1:2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_get_single_element\u001b[0;34m(self, row, col)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmajor_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmajor_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    891\u001b[0m         \u001b[0;31m# can use np.add(..., where) from numpy 1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         return np.compress(minor_index == self.indices[start:end],\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dtmodel_realdata = DecisionTreeModel(sM_training, depth_threshold=3)\n",
    "dtmodel_realdata.build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Calculate RMSE on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_result = pred_RMSE_for_new_item(dtmodel_realdata, sM_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: stop spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dtmodel_realdata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-ff0dfb11b27e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdtmodel_realdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dtmodel_realdata' is not defined"
     ]
    }
   ],
   "source": [
    "dtmodel_realdata.MF.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
